#![allow(dead_code)]
//! # 08: Integration & Deployment - Production-Ready MCP Servers
//!
//! **Learning Goals (30+ minutes):**
//! - Build production-ready MCP servers with complete integration
//! - Implement configuration management and environment handling
//! - Add comprehensive monitoring, health checks, and observability
//! - Learn deployment strategies and operational best practices
//!
//! **What this example demonstrates:**
//! - Multi-environment configuration management (dev/staging/prod)
//! - Health checks and readiness probes for orchestration
//! - Structured logging with correlation IDs and tracing
//! - Metrics exportation for monitoring systems (Prometheus-style)
//! - Graceful shutdown and cleanup procedures
//! - Service discovery and external system integration
//! - Error tracking and alerting integration
//! - Database connections and migration handling
//!
//! **Run with:**
//! ```bash
//! # Development mode
//! cargo run --example 08_integration
//!
//! # Production mode with config
//! ENVIRONMENT=production CONFIG_PATH=./config/prod.toml cargo run --example 08_integration
//! ```

use serde::{Deserialize, Serialize};
use std::collections::HashMap;
use std::env;
use std::sync::Arc;
use std::time::{Duration, Instant, SystemTime, UNIX_EPOCH};
use tokio::signal;
use tokio::sync::{Mutex, RwLock};
use tracing::{error, info, instrument, warn};
use turbomcp::prelude::*;

/// Production-ready MCP server with complete integration capabilities
///
/// This server demonstrates enterprise-grade patterns:
/// - Multi-environment configuration
/// - Health checks and metrics endpoints  
/// - Database connection management
/// - Service discovery integration
/// - Graceful shutdown handling
/// - Comprehensive observability
#[derive(Debug, Clone)]
struct IntegratedServer {
    /// Runtime configuration
    config: Arc<AppConfig>,
    /// Application state and metrics
    state: Arc<AppState>,
    /// Database connection pool
    db_pool: Arc<DatabasePool>,
    /// External service clients
    services: Arc<ExternalServices>,
    /// Health check manager
    health: Arc<HealthManager>,
    /// Metrics collector
    metrics: Arc<MetricsCollector>,
}

#[derive(Debug, Clone, Deserialize)]
struct AppConfig {
    /// Environment (dev, staging, prod)
    environment: Environment,
    /// Server configuration
    server: ServerConfig,
    /// Database configuration
    database: DatabaseConfig,
    /// External services configuration
    services: ServicesConfig,
    /// Monitoring and observability
    monitoring: MonitoringConfig,
    /// Feature flags
    features: FeatureFlags,
}

#[derive(Debug, Clone, Deserialize, PartialEq)]
enum Environment {
    #[serde(rename = "development")]
    Development,
    #[serde(rename = "staging")]
    Staging,
    #[serde(rename = "production")]
    Production,
}

#[derive(Debug, Clone, Deserialize)]
struct ServerConfig {
    host: String,
    port: u16,
    max_connections: usize,
    request_timeout_seconds: u64,
    graceful_shutdown_timeout_seconds: u64,
    enable_metrics: bool,
    enable_health_checks: bool,
}

#[derive(Debug, Clone, Deserialize)]
struct DatabaseConfig {
    url: String,
    max_connections: u32,
    min_connections: u32,
    connection_timeout_seconds: u64,
    idle_timeout_seconds: u64,
    max_lifetime_seconds: u64,
    enable_migrations: bool,
}

#[derive(Debug, Clone, Deserialize)]
struct ServicesConfig {
    auth_service_url: String,
    metrics_service_url: String,
    file_storage_url: String,
    notification_service_url: String,
    timeout_seconds: u64,
    retry_attempts: u32,
    circuit_breaker_threshold: u32,
}

#[derive(Debug, Clone, Deserialize)]
struct MonitoringConfig {
    enable_tracing: bool,
    jaeger_endpoint: Option<String>,
    prometheus_endpoint: Option<String>,
    log_level: String,
    enable_error_reporting: bool,
    sentry_dsn: Option<String>,
}

#[derive(Debug, Clone, Deserialize)]
struct FeatureFlags {
    enable_caching: bool,
    enable_rate_limiting: bool,
    enable_request_logging: bool,
    enable_performance_monitoring: bool,
    experimental_features: bool,
}

#[derive(Debug)]
struct AppState {
    start_time: Instant,
    version: String,
    build_info: BuildInfo,
    request_count: Mutex<u64>,
    error_count: Mutex<u64>,
    active_connections: Mutex<u64>,
    last_health_check: Mutex<SystemTime>,
}

#[derive(Debug)]
struct BuildInfo {
    version: String,
    commit_hash: String,
    build_time: String,
    rust_version: String,
}

#[derive(Debug)]
struct DatabasePool {
    // Simulate database connection pool
    connections: Mutex<Vec<DatabaseConnection>>,
    config: DatabaseConfig,
    health_status: RwLock<HealthStatus>,
}

#[derive(Debug)]
struct DatabaseConnection {
    id: u64,
    created_at: SystemTime,
    last_used: SystemTime,
    is_healthy: bool,
}

#[derive(Debug)]
struct ExternalServices {
    auth_client: AuthServiceClient,
    metrics_client: MetricsServiceClient,
    storage_client: StorageServiceClient,
    notification_client: NotificationServiceClient,
}

#[derive(Debug)]
struct AuthServiceClient {
    base_url: String,
    timeout: Duration,
}

#[derive(Debug)]
struct MetricsServiceClient {
    base_url: String,
    timeout: Duration,
}

#[derive(Debug)]
struct StorageServiceClient {
    base_url: String,
    timeout: Duration,
}

#[derive(Debug)]
struct NotificationServiceClient {
    base_url: String,
    timeout: Duration,
}

#[derive(Debug)]
struct HealthManager {
    checks: RwLock<HashMap<String, HealthCheck>>,
}

#[derive(Debug, Clone)]
struct HealthCheck {
    name: String,
    status: HealthStatus,
    last_check: SystemTime,
    check_interval: Duration,
    timeout: Duration,
    error_message: Option<String>,
}

#[derive(Debug, Clone, PartialEq)]
enum HealthStatus {
    Healthy,
    Unhealthy,
    Unknown,
}

#[derive(Debug)]
struct MetricsCollector {
    metrics: RwLock<HashMap<String, MetricValue>>,
    start_time: Instant,
}

#[derive(Debug, Clone)]
enum MetricValue {
    Counter(u64),
    Gauge(f64),
    Histogram { buckets: Vec<f64>, counts: Vec<u64> },
    Summary { count: u64, sum: f64 },
}

// Request/Response types for the MCP tools
#[derive(Debug, Deserialize, Serialize)]
struct HealthCheckRequest {
    include_details: Option<bool>,
    check_external_services: Option<bool>,
}

#[derive(Debug, Serialize)]
struct HealthCheckResponse {
    status: String,
    timestamp: String,
    uptime_seconds: u64,
    version: String,
    environment: String,
    checks: HashMap<String, HealthCheckResult>,
}

#[derive(Debug, Serialize)]
struct HealthCheckResult {
    status: String,
    last_check: String,
    error: Option<String>,
    response_time_ms: Option<u64>,
}

#[derive(Debug, Deserialize, Serialize)]
struct MetricsRequest {
    format: Option<String>, // "prometheus", "json"
    filter: Option<String>,
}

#[derive(Debug, Serialize, Deserialize)]
struct ConfigurationRequest {
    section: Option<String>,
    include_sensitive: Option<bool>,
}

#[derive(Debug, Serialize)]
struct ConfigurationResponse {
    environment: String,
    sections: HashMap<String, serde_json::Value>,
    features: HashMap<String, bool>,
}

// =============================================================================
// IMPLEMENTATION DETAILS
// =============================================================================

impl AppConfig {
    fn load() -> Result<Self, Box<dyn std::error::Error>> {
        let environment = env::var("ENVIRONMENT").unwrap_or_else(|_| "development".to_string());
        let config_path =
            env::var("CONFIG_PATH").unwrap_or_else(|_| format!("config/{environment}.toml"));

        info!(
            "Loading configuration from: {} (environment: {})",
            config_path, environment
        );

        // In a real implementation, you would load from TOML/YAML/JSON files
        // For this example, we create a default configuration
        let config = match environment.as_str() {
            "production" => Self::production_config(),
            "staging" => Self::staging_config(),
            _ => Self::development_config(),
        };

        Ok(config)
    }

    fn development_config() -> Self {
        Self {
            environment: Environment::Development,
            server: ServerConfig {
                host: "127.0.0.1".to_string(),
                port: 3000,
                max_connections: 100,
                request_timeout_seconds: 30,
                graceful_shutdown_timeout_seconds: 10,
                enable_metrics: true,
                enable_health_checks: true,
            },
            database: DatabaseConfig {
                url: "sqlite://./dev.db".to_string(),
                max_connections: 10,
                min_connections: 1,
                connection_timeout_seconds: 10,
                idle_timeout_seconds: 300,
                max_lifetime_seconds: 3600,
                enable_migrations: true,
            },
            services: ServicesConfig {
                auth_service_url: "http://localhost:8001".to_string(),
                metrics_service_url: "http://localhost:8002".to_string(),
                file_storage_url: "http://localhost:8003".to_string(),
                notification_service_url: "http://localhost:8004".to_string(),
                timeout_seconds: 30,
                retry_attempts: 3,
                circuit_breaker_threshold: 5,
            },
            monitoring: MonitoringConfig {
                enable_tracing: true,
                jaeger_endpoint: Some("http://localhost:14268".to_string()),
                prometheus_endpoint: Some("http://localhost:9090".to_string()),
                log_level: "debug".to_string(),
                enable_error_reporting: false,
                sentry_dsn: None,
            },
            features: FeatureFlags {
                enable_caching: true,
                enable_rate_limiting: false,
                enable_request_logging: true,
                enable_performance_monitoring: true,
                experimental_features: true,
            },
        }
    }

    fn staging_config() -> Self {
        let mut config = Self::development_config();
        config.environment = Environment::Staging;
        config.server.host = "0.0.0.0".to_string();
        config.server.port = 8080;
        config.features.experimental_features = false;
        config.monitoring.log_level = "info".to_string();
        config
    }

    fn production_config() -> Self {
        let mut config = Self::staging_config();
        config.environment = Environment::Production;
        config.server.max_connections = 1000;
        config.database.max_connections = 50;
        config.features.enable_rate_limiting = true;
        config.features.experimental_features = false;
        config.monitoring.log_level = "warn".to_string();
        config.monitoring.enable_error_reporting = true;
        config
    }
}

#[turbomcp::server(name = "IntegratedServer", version = "1.0.0")]
impl IntegratedServer {
    async fn new(config: AppConfig) -> Result<Self, Box<dyn std::error::Error>> {
        info!(
            "Initializing integrated server for environment: {:?}",
            config.environment
        );

        let build_info = BuildInfo {
            version: env!("CARGO_PKG_VERSION").to_string(),
            commit_hash: env::var("GIT_COMMIT").unwrap_or_else(|_| "unknown".to_string()),
            build_time: env::var("BUILD_TIME").unwrap_or_else(|_| "unknown".to_string()),
            rust_version: env::var("RUST_VERSION").unwrap_or_else(|_| "unknown".to_string()),
        };

        let state = Arc::new(AppState {
            start_time: Instant::now(),
            version: build_info.version.clone(),
            build_info,
            request_count: Mutex::new(0),
            error_count: Mutex::new(0),
            active_connections: Mutex::new(0),
            last_health_check: Mutex::new(SystemTime::now()),
        });

        let db_pool = Arc::new(DatabasePool::new(config.database.clone()).await?);
        let services = Arc::new(ExternalServices::new(&config.services).await?);
        let health = Arc::new(HealthManager::new());
        let metrics = Arc::new(MetricsCollector::new());

        // Initialize health checks
        health
            .register_check("database", Duration::from_secs(30))
            .await;
        health
            .register_check("auth_service", Duration::from_secs(60))
            .await;
        health
            .register_check("metrics_service", Duration::from_secs(60))
            .await;

        Ok(Self {
            config: Arc::new(config),
            state,
            db_pool,
            services,
            health,
            metrics,
        })
    }

    #[instrument(skip(self))]
    async fn run_health_checks(&self) -> Result<(), Box<dyn std::error::Error>> {
        info!("Running periodic health checks");

        // Database health check
        let db_healthy = self.db_pool.health_check().await;
        self.health.update_check("database", db_healthy, None).await;

        // External services health checks
        let auth_healthy = self.services.auth_client.health_check().await;
        self.health
            .update_check("auth_service", auth_healthy, None)
            .await;

        let metrics_healthy = self.services.metrics_client.health_check().await;
        self.health
            .update_check("metrics_service", metrics_healthy, None)
            .await;

        Ok(())
    }

    async fn shutdown_gracefully(&self) -> Result<(), Box<dyn std::error::Error>> {
        info!("Starting graceful shutdown sequence");

        let timeout = Duration::from_secs(self.config.server.graceful_shutdown_timeout_seconds);

        // Stop accepting new connections
        info!("Stopping new connection acceptance");

        // Wait for active requests to complete
        let start = Instant::now();
        loop {
            let active = *self.state.active_connections.lock().await;
            if active == 0 || start.elapsed() >= timeout {
                break;
            }
            tokio::time::sleep(Duration::from_millis(100)).await;
        }

        // Clean up resources
        self.db_pool.close_all_connections().await;
        info!("Database connections closed");

        self.metrics.export_final_metrics().await;
        info!("Final metrics exported");

        info!("Graceful shutdown completed");
        Ok(())
    }
}

// Database implementation
impl DatabasePool {
    async fn new(config: DatabaseConfig) -> Result<Self, Box<dyn std::error::Error>> {
        info!(
            "Initializing database pool with max_connections: {}",
            config.max_connections
        );

        Ok(Self {
            connections: Mutex::new(Vec::new()),
            config,
            health_status: RwLock::new(HealthStatus::Unknown),
        })
    }

    async fn health_check(&self) -> bool {
        // Simulate database health check
        let healthy = true; // In reality, you'd ping the database
        let mut status = self.health_status.write().await;
        *status = if healthy {
            HealthStatus::Healthy
        } else {
            HealthStatus::Unhealthy
        };
        healthy
    }

    async fn close_all_connections(&self) {
        let mut connections = self.connections.lock().await;
        connections.clear();
        info!("All database connections closed");
    }
}

// External services implementation
impl ExternalServices {
    async fn new(config: &ServicesConfig) -> Result<Self, Box<dyn std::error::Error>> {
        let timeout = Duration::from_secs(config.timeout_seconds);

        Ok(Self {
            auth_client: AuthServiceClient {
                base_url: config.auth_service_url.clone(),
                timeout,
            },
            metrics_client: MetricsServiceClient {
                base_url: config.metrics_service_url.clone(),
                timeout,
            },
            storage_client: StorageServiceClient {
                base_url: config.file_storage_url.clone(),
                timeout,
            },
            notification_client: NotificationServiceClient {
                base_url: config.notification_service_url.clone(),
                timeout,
            },
        })
    }
}

impl AuthServiceClient {
    async fn health_check(&self) -> bool {
        // Simulate health check call
        true
    }
}

impl MetricsServiceClient {
    async fn health_check(&self) -> bool {
        // Simulate health check call
        true
    }
}

// Health manager implementation
impl HealthManager {
    fn new() -> Self {
        Self {
            checks: RwLock::new(HashMap::new()),
        }
    }

    async fn register_check(&self, name: &str, interval: Duration) {
        let check = HealthCheck {
            name: name.to_string(),
            status: HealthStatus::Unknown,
            last_check: SystemTime::now(),
            check_interval: interval,
            timeout: Duration::from_secs(10),
            error_message: None,
        };

        let mut checks = self.checks.write().await;
        checks.insert(name.to_string(), check);
    }

    async fn update_check(&self, name: &str, healthy: bool, error: Option<String>) {
        let mut checks = self.checks.write().await;
        if let Some(check) = checks.get_mut(name) {
            check.status = if healthy {
                HealthStatus::Healthy
            } else {
                HealthStatus::Unhealthy
            };
            check.last_check = SystemTime::now();
            check.error_message = error;
        }
    }

    async fn get_overall_health(&self) -> HealthStatus {
        let checks = self.checks.read().await;

        if checks.is_empty() {
            return HealthStatus::Unknown;
        }

        let unhealthy_count = checks
            .values()
            .filter(|check| check.status == HealthStatus::Unhealthy)
            .count();

        if unhealthy_count == 0 {
            HealthStatus::Healthy
        } else {
            HealthStatus::Unhealthy
        }
    }
}

// Metrics collector implementation
impl MetricsCollector {
    fn new() -> Self {
        Self {
            metrics: RwLock::new(HashMap::new()),
            start_time: Instant::now(),
        }
    }

    async fn increment_counter(&self, name: &str) {
        let mut metrics = self.metrics.write().await;
        match metrics.get_mut(name) {
            Some(MetricValue::Counter(ref mut count)) => *count += 1,
            _ => {
                metrics.insert(name.to_string(), MetricValue::Counter(1));
            }
        }
    }

    async fn set_gauge(&self, name: &str, value: f64) {
        let mut metrics = self.metrics.write().await;
        metrics.insert(name.to_string(), MetricValue::Gauge(value));
    }

    async fn export_prometheus(&self) -> String {
        let metrics = self.metrics.read().await;
        let mut output = String::new();

        output.push_str("# HELP turbomcp_uptime_seconds Total uptime of the server\n");
        output.push_str("# TYPE turbomcp_uptime_seconds gauge\n");
        output.push_str(&format!(
            "turbomcp_uptime_seconds {}\n",
            self.start_time.elapsed().as_secs()
        ));
        output.push('\n');

        for (name, value) in metrics.iter() {
            match value {
                MetricValue::Counter(count) => {
                    output.push_str(&format!("# HELP {name} Total count\n"));
                    output.push_str(&format!("# TYPE {name} counter\n"));
                    output.push_str(&format!("{name} {count}\n"));
                }
                MetricValue::Gauge(gauge) => {
                    output.push_str(&format!("# HELP {name} Current value\n"));
                    output.push_str(&format!("# TYPE {name} gauge\n"));
                    output.push_str(&format!("{name} {gauge}\n"));
                }
                _ => {} // Skip complex metrics for this example
            }
            output.push('\n');
        }

        output
    }

    async fn export_final_metrics(&self) {
        info!("Exporting final metrics before shutdown");
        // In a real implementation, you would send to monitoring service
    }
}

// =============================================================================
// MCP SERVER IMPLEMENTATION
// =============================================================================

impl IntegratedServer {
    /// Comprehensive health check endpoint for orchestration and monitoring
    #[tool("Get comprehensive health check status for monitoring and orchestration")]
    async fn health_check(
        &self,
        ctx: Context,
        request: HealthCheckRequest,
    ) -> McpResult<HealthCheckResponse> {
        let include_details = request.include_details.unwrap_or(false);
        let check_external = request.check_external_services.unwrap_or(false);

        let _ = ctx.info("Performing health check").await;

        // Update last health check time
        {
            let mut last_check = self.state.last_health_check.lock().await;
            *last_check = SystemTime::now();
        }

        // Run health checks if requested
        if check_external {
            if let Err(e) = self.run_health_checks().await {
                warn!("Health check failed: {}", e);
            }
        }

        let overall_health = self.health.get_overall_health().await;
        let uptime = self.state.start_time.elapsed().as_secs();

        let mut checks = HashMap::new();

        if include_details {
            let health_checks = self.health.checks.read().await;
            for (name, check) in health_checks.iter() {
                checks.insert(
                    name.clone(),
                    HealthCheckResult {
                        status: match check.status {
                            HealthStatus::Healthy => "healthy".to_string(),
                            HealthStatus::Unhealthy => "unhealthy".to_string(),
                            HealthStatus::Unknown => "unknown".to_string(),
                        },
                        last_check: check
                            .last_check
                            .duration_since(UNIX_EPOCH)
                            .unwrap_or_default()
                            .as_secs()
                            .to_string(),
                        error: check.error_message.clone(),
                        response_time_ms: Some(10), // Simulated response time
                    },
                );
            }
        }

        let response = HealthCheckResponse {
            status: match overall_health {
                HealthStatus::Healthy => "healthy".to_string(),
                HealthStatus::Unhealthy => "unhealthy".to_string(),
                HealthStatus::Unknown => "unknown".to_string(),
            },
            timestamp: SystemTime::now()
                .duration_since(UNIX_EPOCH)
                .unwrap_or_default()
                .as_secs()
                .to_string(),
            uptime_seconds: uptime,
            version: self.state.version.clone(),
            environment: format!("{:?}", self.config.environment),
            checks,
        };

        // Update metrics
        self.metrics.increment_counter("health_checks_total").await;
        self.metrics
            .set_gauge("uptime_seconds", uptime as f64)
            .await;

        Ok(response)
    }

    /// Export metrics in various formats for monitoring systems
    #[tool("Export system metrics in Prometheus or JSON format for monitoring")]
    async fn export_metrics(&self, ctx: Context, request: MetricsRequest) -> McpResult<String> {
        let format = request.format.unwrap_or_else(|| "json".to_string());

        let _ = ctx
            .info(&format!("Exporting metrics in {format} format"))
            .await;

        let metrics_data = match format.to_lowercase().as_str() {
            "prometheus" => self.metrics.export_prometheus().await,
            "json" => {
                let metrics = self.metrics.metrics.read().await;
                let json_metrics: HashMap<String, serde_json::Value> = metrics
                    .iter()
                    .map(|(k, v)| {
                        let value = match v {
                            MetricValue::Counter(c) => {
                                serde_json::json!({"type": "counter", "value": c})
                            }
                            MetricValue::Gauge(g) => {
                                serde_json::json!({"type": "gauge", "value": g})
                            }
                            _ => serde_json::json!({"type": "complex", "value": "N/A"}),
                        };
                        (k.clone(), value)
                    })
                    .collect();

                serde_json::to_string_pretty(&serde_json::json!({
                    "timestamp": SystemTime::now()
                        .duration_since(UNIX_EPOCH)
                        .unwrap_or_default()
                        .as_secs(),
                    "uptime_seconds": self.state.start_time.elapsed().as_secs(),
                    "version": self.state.version,
                    "environment": format!("{:?}", self.config.environment),
                    "metrics": json_metrics
                }))
                .unwrap_or_else(|_| "Error serializing metrics".to_string())
            }
            _ => {
                return Err(McpError::invalid_request(format!(
                    "Unsupported format: {format}. Supported: json, prometheus"
                )))
            }
        };

        // Update request metrics
        self.metrics
            .increment_counter("metrics_requests_total")
            .await;

        Ok(metrics_data)
    }

    /// Get runtime configuration information
    #[tool("Get runtime configuration and feature flags")]
    async fn get_configuration(
        &self,
        ctx: Context,
        request: ConfigurationRequest,
    ) -> McpResult<ConfigurationResponse> {
        let section_filter = request.section.as_deref();
        let include_sensitive = request.include_sensitive.unwrap_or(false);

        let _ = ctx.info("Retrieving configuration").await;

        let mut sections = HashMap::new();

        // Add configuration sections based on request
        let add_section = |sections: &mut HashMap<String, serde_json::Value>,
                           name: &str,
                           include: bool| {
            if include && (section_filter.is_none() || section_filter == Some(name)) {
                match name {
                    "server" => {
                        sections.insert(name.to_string(), serde_json::json!({
                            "host": if include_sensitive { &self.config.server.host } else { "***" },
                            "port": self.config.server.port,
                            "max_connections": self.config.server.max_connections,
                            "request_timeout_seconds": self.config.server.request_timeout_seconds,
                        }));
                    }
                    "database" => {
                        sections.insert(name.to_string(), serde_json::json!({
                            "url": if include_sensitive { &self.config.database.url } else { "***" },
                            "max_connections": self.config.database.max_connections,
                            "min_connections": self.config.database.min_connections,
                            "enable_migrations": self.config.database.enable_migrations,
                        }));
                    }
                    "monitoring" => {
                        let jaeger_endpoint = if include_sensitive {
                            &self.config.monitoring.jaeger_endpoint
                        } else {
                            &Some("***".to_string())
                        };
                        sections.insert(name.to_string(), serde_json::json!({
                            "enable_tracing": self.config.monitoring.enable_tracing,
                            "log_level": self.config.monitoring.log_level,
                            "enable_error_reporting": self.config.monitoring.enable_error_reporting,
                            "jaeger_endpoint": jaeger_endpoint,
                        }));
                    }
                    _ => {}
                }
            }
        };

        add_section(&mut sections, "server", true);
        add_section(&mut sections, "database", true);
        add_section(&mut sections, "monitoring", true);

        // Feature flags
        let features = HashMap::from([
            (
                "enable_caching".to_string(),
                self.config.features.enable_caching,
            ),
            (
                "enable_rate_limiting".to_string(),
                self.config.features.enable_rate_limiting,
            ),
            (
                "enable_request_logging".to_string(),
                self.config.features.enable_request_logging,
            ),
            (
                "enable_performance_monitoring".to_string(),
                self.config.features.enable_performance_monitoring,
            ),
            (
                "experimental_features".to_string(),
                self.config.features.experimental_features,
            ),
        ]);

        let response = ConfigurationResponse {
            environment: format!("{:?}", self.config.environment),
            sections,
            features,
        };

        Ok(response)
    }

    /// Process a business operation with full observability
    #[tool("Process business operation with full tracing and error handling")]
    async fn process_business_operation(
        &self,
        ctx: Context,
        operation_id: String,
        operation_type: String,
        data: serde_json::Value,
    ) -> McpResult<serde_json::Value> {
        let span_id = format!("op-{}-{}", operation_id, chrono::Utc::now().timestamp());

        let _ = ctx
            .info(&format!(
                "Processing business operation: {operation_id} ({operation_type})"
            ))
            .await;

        // Increment request counter
        {
            let mut count = self.state.request_count.lock().await;
            *count += 1;
        }

        // Increment active connections
        {
            let mut active = self.state.active_connections.lock().await;
            *active += 1;
        }

        let start_time = Instant::now();

        // Simulate business logic with error handling
        let result = match operation_type.as_str() {
            "create_user" => {
                // Simulate user creation with database interaction
                let _conn = self.db_pool.health_check().await;

                serde_json::json!({
                    "user_id": format!("user_{}", operation_id),
                    "status": "created",
                    "created_at": chrono::Utc::now().to_rfc3339(),
                    "data": data
                })
            }
            "update_profile" => {
                // Simulate profile update with validation
                if !data.is_object() {
                    return Err(McpError::invalid_request("Profile data must be an object"));
                }

                serde_json::json!({
                    "profile_id": operation_id,
                    "status": "updated",
                    "updated_at": chrono::Utc::now().to_rfc3339(),
                    "changes": data
                })
            }
            "send_notification" => {
                // Simulate external service call
                let _healthy = self
                    .services
                    .notification_client
                    .base_url
                    .starts_with("http");

                serde_json::json!({
                    "notification_id": format!("notif_{}", operation_id),
                    "status": "sent",
                    "sent_at": chrono::Utc::now().to_rfc3339(),
                    "recipient": data.get("recipient").unwrap_or(&serde_json::json!("unknown"))
                })
            }
            _ => {
                // Increment error counter
                {
                    let mut errors = self.state.error_count.lock().await;
                    *errors += 1;
                }

                return Err(McpError::invalid_request(format!(
                    "Unknown operation type: {operation_type}"
                )));
            }
        };

        let processing_time = start_time.elapsed();

        // Decrement active connections
        {
            let mut active = self.state.active_connections.lock().await;
            *active = active.saturating_sub(1);
        }

        // Update metrics
        self.metrics.increment_counter("operations_total").await;
        self.metrics
            .set_gauge("operation_duration_seconds", processing_time.as_secs_f64())
            .await;

        let _ = ctx
            .info(&format!(
                "Operation {} completed in {}ms",
                operation_id,
                processing_time.as_millis()
            ))
            .await;

        Ok(serde_json::json!({
            "operation_id": operation_id,
            "span_id": span_id,
            "processing_time_ms": processing_time.as_millis(),
            "result": result,
            "timestamp": chrono::Utc::now().to_rfc3339()
        }))
    }
}

#[tokio::main]
async fn main() -> McpResult<()> {
    // Initialize configuration
    let config =
        AppConfig::load().map_err(|e| McpError::internal(format!("Failed to load config: {e}")))?;

    // Initialize tracing based on config
    tracing_subscriber::fmt()
        .with_env_filter(&config.monitoring.log_level)
        .with_target(false)
        .init();

    info!("🚀 Starting TurboMCP Integrated Server");
    info!("Environment: {:?}", config.environment);
    info!("Version: {}", env!("CARGO_PKG_VERSION"));

    // Create integrated server
    let server = IntegratedServer::new(config)
        .await
        .map_err(|e| McpError::internal(format!("Server initialization failed: {e}")))?;

    info!("✅ Server initialized successfully");

    // Set up graceful shutdown handling
    let server_clone = server.clone();
    tokio::spawn(async move {
        match signal::ctrl_c().await {
            Ok(()) => {
                info!("Received Ctrl+C, initiating graceful shutdown...");
                if let Err(e) = server_clone.shutdown_gracefully().await {
                    error!("Error during graceful shutdown: {}", e);
                }
                std::process::exit(0);
            }
            Err(err) => {
                error!("Unable to listen for shutdown signal: {}", err);
            }
        }
    });

    // Start periodic health checks
    let health_server = server.clone();
    tokio::spawn(async move {
        let mut interval = tokio::time::interval(Duration::from_secs(30));
        loop {
            interval.tick().await;
            if let Err(e) = health_server.run_health_checks().await {
                warn!("Periodic health check failed: {}", e);
            }
        }
    });

    info!("🔥 Server ready for connections");
    info!("Available endpoints:");
    info!("  • health_check - Comprehensive health monitoring");
    info!("  • export_metrics - Prometheus/JSON metrics export");
    info!("  • get_configuration - Runtime configuration access");
    info!("  • process_business_operation - Full-stack business operations");

    // Run the MCP server
    server
        .run_stdio()
        .await
        .map_err(|e| McpError::internal(format!("Server error: {e}")))
}

// 🎯 **Integration Examples:**
//
//    Health monitoring:
//    - health_check({ "include_details": true, "check_external_services": true })
//
//    Metrics export:
//    - export_metrics({ "format": "prometheus" })
//    - export_metrics({ "format": "json", "filter": "requests" })
//
//    Configuration access:
//    - get_configuration({ "section": "server", "include_sensitive": false })
//
//    Business operations:
//    - process_business_operation("user123", "create_user", { "name": "John", "email": "john@example.com" })
//    - process_business_operation("profile456", "update_profile", { "bio": "Updated bio" })

/* 📝 **Production Integration Patterns:**

**Configuration Management:**
- Environment-specific configs (dev/staging/prod)
- Feature flags for gradual rollouts
- Sensitive data handling and secret management
- Runtime configuration updates

**Observability & Monitoring:**
- Structured logging with correlation IDs
- Distributed tracing integration (Jaeger/Zipkin)
- Prometheus metrics export
- Custom business metrics collection
- Error tracking and alerting (Sentry)

**Health & Reliability:**
- Comprehensive health checks for orchestration
- Circuit breaker patterns for external services
- Graceful shutdown with connection draining
- Database connection pooling and management

**Deployment & Operations:**
- Docker containerization support
- Kubernetes readiness and liveness probes
- Service discovery integration
- Load balancer health endpoints
- Blue/green deployment compatibility

**Security & Compliance:**
- Authentication service integration
- Request/response logging for audit trails
- Rate limiting and DDoS protection
- Sensitive data redaction in logs

**Performance & Scalability:**
- Connection pooling for expensive resources
- Request batching and bulk operations
- Caching strategies with TTL management
- Resource cleanup and memory management

**This completes the comprehensive 8-example series demonstrating TurboMCP from beginner to production-ready implementations.**
*/
