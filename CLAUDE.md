# TurboMCP Engineering Philosophy & Standards

## üö® CRITICAL: ZERO TOLERANCE ENFORCEMENT - READ FIRST

**THIS PROJECT OVERRIDES WORKSPACE DEFAULTS WITH STRICTER STANDARDS**

## üß† MANDATORY: ULTRATHINK METHOD - APPLY BEFORE CODING

**Every task requires the complete Ultrathink workflow:**
1. **Analyze deeply** - Understand the complete architecture, dependencies, and requirements
2. **Plan comprehensively** - Use TodoWrite to track ALL aspects of the solution with rich context
3. **Research thoroughly** - Use WebSearch for latest documentation of any libraries being used
4. **Implement methodically** - TDD: failing tests first, then production-grade implementation
5. **Validate completely** - Test actual behavior with real services, comprehensive edge cases
6. **Enforce continuously** - Run all quality gates before claiming completion

**If you haven't completed steps 1-3, you are not ready to write code. Period.**

## üéØ Core Philosophy: "Test-Driven Excellence with World-Class Libraries"

**FUNDAMENTAL RULE: NO MOCKS, NO PLACEHOLDERS, NO NAIVE IMPLEMENTATIONS. EVER. ANYWHERE.**

TurboMCP is built on the principle that **every implementation must be production-ready, enterprise-grade quality from day one**. We've learned the hard way that mocks and placeholders create massive technical debt that undermines the entire codebase.

### The Critical Lesson Learned
Our macro system was initially mocked, causing:
- Tests written against fake APIs that never existed
- Examples that couldn't compile when real implementation was added
- Months of technical debt requiring complete system rewrites
- Broken user experience and developer confusion

**We prevent this from EVER happening again.**

### The Golden Rule
**"Implementation complexity ‚â† User complexity"**

We handle the hard problems so users don't have to. Every API decision is evaluated through the lens of maximum developer experience (DX) and ergonomics.

## üöÄ Production Standards

### 0. TEST-DRIVEN DEVELOPMENT IS MANDATORY
**Every implementation must follow TDD with production-grade quality:**

#### The TDD Workflow (NON-NEGOTIABLE):
1. **Write failing tests FIRST** - Test the actual behavior you're about to implement
2. **Verify tests fail** - Run them to ensure they actually test something meaningful
3. **Implement production code** - Write world-class implementation to make tests pass
4. **Verify tests pass** - Ensure all tests validate real behavior, not mocks
5. **Refactor for excellence** - Optimize for performance, security, maintainability
6. **Run comprehensive validation** - All quality gates must pass

#### Zero Tolerance Implementation Rules:
- ‚ùå **NEVER** use placeholder implementations "to be filled later" or "in a real implementation"
- ‚ùå **NEVER** use mocks in place of real functionality - Use Docker/Testcontainers instead
- ‚ùå **NEVER** use `todo!()`, `unimplemented!()`, or similar shortcuts in code
- ‚ùå **NEVER** write tests against non-existent or fake APIs
- ‚ùå **NEVER** claim "robust implementation" while delivering shortcuts
- ‚úÖ **ALWAYS** implement complete, robust, production-ready code with full functionality
- ‚úÖ **ALWAYS** test against real implementations using Docker for services
- ‚úÖ **ALWAYS** build with the assumption this code goes to production immediately
- ‚úÖ **ALWAYS** use TodoWrite for planning - never leave placeholders in code
- ‚úÖ **ALWAYS** research and use best-in-class libraries (check docs.rs, crates.io, WebSearch)
- ‚úÖ **ALWAYS** verify latest documentation before using any library APIs

**"No shortcuts. No excuses. Production-grade or nothing."**

### 1. Never Compromise Functionality for Simplicity
- When faced with complex architectural decisions, we choose the solution that preserves maximum capability
- Simplification is only acceptable when it genuinely improves the user experience without removing functionality
- **Example**: Our Context API could have been "simplified" to basic logging, but we implemented Send-safe format arguments for truly ergonomic usage

### 2. Question Every Simplification - Engineering Excellence Over Shortcuts
Before removing or simplifying functionality, we ask:
- **"Are we being lazy or is this genuinely better?"**
- **"Does this regress functionality, ergonomics, or extensibility?"**
- **"Would a world-class production-grade implementation solve this differently?"**
- **"Have we researched how leading libraries solve this problem?"**
- **"Are we taking shortcuts that will create technical debt?"**

**If the answer reveals laziness or shortcuts, stop and implement properly.**

### 3. Beautiful APIs Through Deep Engineering
Our most ergonomic features often require the most sophisticated implementation:

**‚ùå Lazy Approach:**
```rust
ctx.info(&format!("Processing {} items", count)).await;
//       ^^^^^^^^                      ^^  ^^^^^
//       manual   nested parentheses   |   positioning confusion
```

**‚úÖ Production-Grade Approach:**
```rust
ctx_info!(ctx, "Processing {} items", count);
//        ^                               ^
//        clean, intuitive, zero issues
```

The production-grade approach required solving Send-safety, macro hygiene, and async positioning - but users get perfect ergonomics.

## üõ† Technical Excellence Standards

### Macro System
- **Zero boilerplate**: Automatic handler registration and trait implementation
- **Type safety**: Compile-time parameter validation and schema generation
- **Context injection**: Flexible Context parameter placement in any position
- **Ergonomic helpers**: `mcp_error!`, `mcp_text!`, `ctx_info!` for clean code

### Error Handling
- **Rich error types**: Comprehensive error variants with context
- **Ergonomic macros**: `mcp_error!("Connection failed: {}", error)` 
- **Automatic conversion**: Seamless error type conversions throughout the stack

### Async Architecture
- **Send-safe throughout**: All APIs work correctly in multi-threaded async contexts
- **Zero-cost abstractions**: Maximum performance without sacrificing ergonomics
- **Proper lifetime management**: No unnecessary clones or allocations

### Testing Philosophy - TEST-DRIVEN EXCELLENCE
**TDD is not optional. Every feature requires tests written BEFORE implementation.**

#### Test-First Development:
1. **Write comprehensive test suite first** - Cover happy path, edge cases, error conditions
2. **Verify tests fail meaningfully** - Tests must actually validate behavior
3. **Implement to pass tests** - Production-grade code that satisfies all test cases
4. **Add more tests as needed** - Discovery during implementation requires new tests
5. **Never skip test writing** - No implementation without tests, period

#### Testing Standards:
- **Dogfooding first**: We use our own APIs extensively in examples and tests
- **Real-world validation**: Complex examples reveal API design issues early
- **Comprehensive coverage**: Every feature tested in realistic scenarios
- **Zero-tolerance quality**: No fraudulent tests, no void patterns, no testing third-party libraries
- **Integration first**: Test the complete macro‚Üíschema‚Üíprotocol chain, not isolated parts
- **Direct validation**: Test actual implementation output, not mocks or placeholders
- **Real services only**: Docker, Testcontainers, actual databases - never mocks

### Real Service Testing - 2025 Best Practices
- **No Mocks, Real Services**: Use Docker Compose and Testcontainers for real service dependencies
- **Best-in-Class Libraries**: SQLx for databases, testcontainers-rs for integration tests
- **Production Parity**: Tests run against the same services used in production
- **Dynamic Infrastructure**: Testcontainers with dynamic ports, proper wait strategies
- **Latest Versions**: PostgreSQL 16+, SQLx with compile-time checked queries
- **Proper Lifecycle**: Containers auto-cleanup, environment isolation per test

```rust
// Example: Real PostgreSQL testing with Testcontainers
use testcontainers::{runners::AsyncRunner, GenericImage, ImageExt};
use sqlx::PgPool;

#[tokio::test]
async fn test_database_operations() {
    let postgres = GenericImage::new("postgres", "16-alpine")
        .with_exposed_port(5432.tcp())
        .with_wait_for(WaitFor::message_on_stdout("ready to accept connections"))
        .with_env_var("POSTGRES_PASSWORD", "test")
        .start().await.unwrap();
    
    let port = postgres.get_host_port_ipv4(5432).await;
    let pool = PgPool::connect(&format!("postgres://postgres:test@localhost:{}/postgres", port))
        .await.unwrap();
    
    // Test actual database operations, not mocks
    sqlx::query!("CREATE TABLE users (id SERIAL PRIMARY KEY, name TEXT NOT NULL)")
        .execute(&pool).await.unwrap();
}
```

## ‚ö° The Anti-Gaslighting Enforcement Protocol

**MANDATORY: Run these checks before claiming ANY task is complete:**

```bash
# 1. ZERO compile errors across entire workspace (no hidden issues)
cargo check --workspace --all-targets --all-features

# 2. ALL examples compile and demonstrate real functionality
cargo check --examples

# 3. ALL tests pass using real implementations only  
cargo test --workspace

# 4. Search and destroy any remaining mocks/placeholders/fake implementations
rg -i "todo\!|unimplemented\!|placeholder|mock|stub|dummy|fake|example" --type rust

# 5. Verify no gaslighting comments exist
rg -i "would be|could be|should be|real implementation|production would|in practice" --type rust

# 6. Verify real service integration tests pass
docker compose up -d  # Start all required services
cargo test --package turbomcp --test "*integration*" -- --test-threads=1
docker compose down  # Clean up

# 7. Verify no "temporary" or "hack" comments exist
rg -i "hack|temp|fixme|xxx|TODO|FIXME" --type rust

# 8. Run zero-tolerance test quality enforcement
cargo test --package turbomcp --test zero_tolerance_enforcement

# 9. Verify no fraudulent test patterns
rg "assert_eq!\(2 \+ 2, 4\)|assert_eq!\(1 \+ 1, 2\)|assert!\(true\)" --type rust
rg "assert_eq!\(\d+, \d+\)" --type rust  # Check for any literal number comparisons

# 10. Check for void patterns that discard results
rg "let _ = .*\.(await|unwrap)" --type rust | grep -v "// OK:"

# 11. Verify tests actually test our code, not third-party libraries
rg "use schemars::" --type rust tests/  # Should only be in src/, not tests/
```

**If ANY of these fail, you have NOT completed the task. Do not claim otherwise.**

## üîç AST-GREP: Rust Code Manipulation Superpower

### Quick Reference
**Docs**: `/Users/nickpaterno/work/reference/ast-grep.github.io/` ‚Ä¢ **Playground**: https://ast-grep.github.io/playground.html

### Essential Rust Patterns Cheatsheet

#### Meta Variables (Pattern Wildcards)
```
$VAR            # Single AST node (e.g., variable, expression)
$$$VARS         # Zero or more nodes
$_VAR           # Non-capturing match (match but don't reuse)
$$VAR           # Capture unnamed nodes (operators, keywords)
```

#### Common Rust Patterns

##### Function & Method Patterns
```bash
# Find all async functions
ast-grep -p 'async fn $NAME($$$PARAMS) -> $RET { $$$BODY }' --lang rust

# Find trait implementations
ast-grep -p 'impl $TRAIT for $TYPE { $$$BODY }' --lang rust

# Find all #[tool] attributes
ast-grep -p '#[tool($$$ARGS)]' --lang rust

# Find Result<T, E> returns
ast-grep -p 'fn $NAME($$$) -> Result<$OK, $ERR>' --lang rust

# Find all .await calls
ast-grep -p '$EXPR.await' --lang rust

# Find all unwrap() calls (for safety audit)
ast-grep -p '$EXPR.unwrap()' --lang rust

# Find ServerBuilder pattern usage
ast-grep -p 'ServerBuilder::new().$$$METHODS.build()' --lang rust
```

##### Struct & Enum Patterns
```bash
# Find all pub structs
ast-grep -p 'pub struct $NAME { $$$FIELDS }' --lang rust

# Find derive macros
ast-grep -p '#[derive($$$DERIVES)]' --lang rust

# Find all Arc<RwLock<T>> patterns
ast-grep -p 'Arc<RwLock<$TYPE>>' --lang rust

# Find DashMap usage
ast-grep -p 'DashMap<$KEY, $VALUE>' --lang rust
```

##### Error Handling Patterns
```bash
# Find all ? operators
ast-grep -p '$EXPR?' --lang rust

# Find map_err usage
ast-grep -p '$EXPR.map_err($CLOSURE)' --lang rust

# Find all McpError constructions
ast-grep -p 'McpError::$VARIANT { $$$FIELDS }' --lang rust
```

### TurboMCP-Specific Patterns

```bash
# Find all tool handler registrations
ast-grep -p '.tool($NAME, $HANDLER)' --lang rust crates/

# Find all roots configurations
ast-grep -p '.roots($ROOTS)' --lang rust crates/

# Find all #[turbomcp::server] macros
ast-grep -p '#[turbomcp::server($$$)]' --lang rust crates/

# Find all Context usage
ast-grep -p 'ctx: Context' --lang rust crates/

# Find all McpResult returns
ast-grep -p '-> McpResult<$TYPE>' --lang rust crates/

# Find all registry operations
ast-grep -p 'self.registry.$METHOD($$$ARGS)' --lang rust crates/

# Audit for todo!() or unimplemented!()
ast-grep -p 'todo!()' --lang rust crates/
ast-grep -p 'unimplemented!()' --lang rust crates/
```

### Advanced Pattern Techniques

#### Pattern Objects for Context-Aware Matching
When simple string patterns fail due to parsing ambiguity, use pattern objects:

```bash
# For complex patterns that need context
ast-grep --lang rust --config - <<EOF
rule:
  pattern:
    context: 'impl ToolHandler for $TYPE { $$$METHODS }'
    selector: function_item
EOF
```

#### Multi Meta Variables for Flexible Matching
```bash
# Match functions with any number of parameters
ast-grep -p 'fn $NAME($$$PARAMS) -> $RET { $$$BODY }' --lang rust

# Match tool calls with any arguments
ast-grep -p 'call_tool($NAME, $$$ARGS)' --lang rust

# Match impl blocks with any methods
ast-grep -p 'impl $TRAIT for $TYPE { $$$METHODS }' --lang rust
```

#### Strictness Levels for Different Match Precision
```bash
# Using YAML config for precise control
ast-grep --lang rust --config - <<EOF
rule:
  pattern:
    context: 'async fn $NAME($$$) -> McpResult<$T>'
    strictness: cst  # All nodes must match exactly
EOF
```

#### Advanced Trait Implementation Hunting
```bash
# Find all async trait implementations  
ast-grep -p 'impl $TRAIT for $TYPE' --lang rust | grep -A 10 -B 2 async

# Find specific trait method implementations
ast-grep --lang rust --config - <<EOF
rule:
  pattern:
    context: 'impl ToolHandler for $TYPE { async fn call($$$) -> $RET { $$$BODY } }'
    selector: function_item
EOF
```

### Code Transformation Examples

#### Replace unwrap() with proper error handling
```bash
# Find problematic unwrap
ast-grep -p '$EXPR.unwrap()' --lang rust

# Replace with ? operator
ast-grep -p '$EXPR.unwrap()' -r '$EXPR?' --lang rust

# Or with proper error context
ast-grep -p '$EXPR.unwrap()' -r '$EXPR.map_err(|e| McpError::Tool(format!("Failed: {}", e)))?' --lang rust
```

#### Modernize string formatting
```bash
# Find old format! patterns
ast-grep -p 'format!("{}", $VAR)' --lang rust

# Replace with inline formatting
ast-grep -p 'format!("{}", $VAR)' -r 'format!("{VAR}")' --lang rust
```

#### Fix common Rust pitfalls
```bash
# Fix char iteration footgun
ast-grep -p '$STR.chars().enumerate()' -r '$STR.char_indices()' --lang rust

# Fix unnecessary clones
ast-grep -p '$VAR.clone()' --lang rust  # Review each for necessity
```

### YAML Rule Examples for Project Validation

#### Detect duplicate exports (save as `.ast-grep/rules/no-duplicate-export.yml`)
```yaml
id: avoid-duplicate-export
language: rust
rule:
  all:
    - pattern: pub use $B::$C;
    - inside:
       kind: source_file
       has:
         pattern: pub mod $A;
    - has:
       pattern: $A
       stopBy: end
message: "Duplicate export: $C is exported from both module and re-export"
```

#### Enforce error handling in async functions
```yaml
id: async-error-handling
language: rust
rule:
  pattern: async fn $NAME($$$) -> $RET { $$$BODY }
  not:
    has:
      pattern: Result<$OK, $ERR>
message: "Async function should return Result for proper error handling"
```

### Performance Tips

1. **Use `kind:` for faster matching** when you know the AST node type
2. **Order patterns by selectivity**: kind > pattern > regex
3. **Use `--threads` for parallel processing on large codebases
4. **Cache patterns** in sgconfig.yml for repeated use

### Integration with TurboMCP Development

```bash
# Before committing: Find all quality issues
ast-grep scan  # Run all configured rules

# Refactor across codebase
ast-grep -p 'old_pattern' -r 'new_pattern' --lang rust --interactive

# Generate report of code patterns
ast-grep -p '$PATTERN' --lang rust --json | jq '.matches | length'

# Find similar code for DRY refactoring
ast-grep -p 'fn $NAME($$$) -> McpResult<$RET> { $$$BODY }' --lang rust
```

### Common AST Node Types in Rust

- `function_item` - Function definitions
- `impl_item` - Impl blocks
- `struct_item` - Struct definitions
- `use_declaration` - Use statements
- `macro_invocation` - Macro calls
- `attribute_item` - Attributes like #[derive()]
- `await_expression` - .await calls
- `try_expression` - ? operator

### Pro Tips

1. **Test patterns in playground first**: https://ast-grep.github.io/playground.html
2. **Use `--debug-query` to see AST structure**
3. **Combine with ripgrep** for initial discovery: `rg pattern | ast-grep refine`
4. **Create project rules** in `.ast-grep/rules/` for consistent enforcement
5. **Use ast-grep in CI** for automatic code quality checks

## üìã Development Commands

Essential commands for maintaining production standards:

### Command Compatibility Notes
**IMPORTANT: macOS Compatibility**
- Use `sleep` command for delays, NOT `timeout` or `gtimeout` (not available on macOS by default)
- Example: `sleep 5` to wait 5 seconds
- For timeouts in tests, use Rust's built-in timeout mechanisms or tokio's timeout functions

### Service Management & Testing
```bash
# Start development services (PostgreSQL, Redis, etc.)
docker compose up -d

# Run tests against real services
cargo test --workspace

# Integration tests with real database
cargo test --package turbomcp --test "*integration*" -- --test-threads=1

# Stop all services and clean up
docker compose down --volumes
```

### Testing & Validation
```bash
# Run comprehensive test suite
cargo test --workspace

# Validate all examples compile (critical DX validation)  
cargo check --examples

# Performance benchmarks
cargo bench

# Code coverage analysis
cargo tarpaulin --out html
```

### Quality Assurance
```bash
# Lint and format (maintain high code quality)
cargo fmt --all
cargo clippy --all-targets --all-features

# Documentation validation
cargo doc --no-deps --workspace
```

### Example Validation (Critical for DX)
Our examples serve as both documentation and API validation:
```bash
# Verify all examples demonstrate proper usage
for i in {01..09}; do
  echo "Testing example $i..."
  cargo run --example ${i}_*
done
```

## üéñ Quality Metrics

### API Ergonomics Checklist
- [ ] Zero manual boilerplate required
- [ ] Intuitive naming following Rust conventions  
- [ ] Helpful compiler errors with clear guidance
- [ ] Examples demonstrate real-world usage patterns
- [ ] No awkward nested parentheses or manual formatting

### Performance Standards
- [ ] Send-safe in all async contexts
- [ ] Zero unnecessary allocations in hot paths
- [ ] Compile-time optimizations where possible
- [ ] Memory-efficient data structures

### Documentation Excellence
- [ ] Every public API documented with examples
- [ ] Complex features explained with tutorials
- [ ] Common patterns demonstrated in examples
- [ ] Error scenarios covered with recovery strategies

## üåü Success Stories

### Context API Evolution
**Problem**: Complex, error-prone logging syntax that every example struggled with  
**Solution**: Send-safe ergonomic macros that work beautifully in async contexts  
**Result**: `ctx_info!(ctx, "Processing {} items", count)` - simple, clean, powerful

### Macro System Architecture
**Problem**: Users forced to write boilerplate handler registration code  
**Solution**: Comprehensive procedural macros with automatic extraction and registration  
**Result**: `#[tool]` functions automatically become MCP tools with full type safety

### Error Handling Transformation  
**Problem**: Verbose error creation and inconsistent error types  
**Solution**: Ergonomic `mcp_error!` macro with automatic type conversion  
**Result**: `mcp_error!("Failed to process: {}", error)` - concise and expressive

### Test Suite Transformation (The Great Awakening) üèÜ
**Problem**: Systemic testing fraud with 70+ void patterns, mathematical gaslighting, wrong-system testing  
**Solution**: Complete overhaul with public metadata access, direct tool testing, zero-tolerance enforcement  
**Result**: Production-grade test suite that caught critical schema bug, validates real implementation

**What Was Built:**
- **Enhanced macro system** with public metadata access (`tool_name_metadata()`)
- **Direct testing capability** (`test_tool_call()`) without transport layer
- **11 comprehensive integration tests** validating macro‚Üíschema‚Üíprotocol chain
- **Zero-tolerance enforcement** preventing test fraud with automated scanning
- **Comprehensive validation** of parameter types, optional handling, error paths

**Critical Bug Prevention:**
The schema bug where `let (name, desc, _schema) = metadata()` was ignoring schemas would now be **impossible** - our tests validate every schema contains actual parameter information.

## üîÑ Continuous Improvement

We continuously evaluate and improve our APIs based on real usage patterns discovered through:
- **Dogfooding**: Extensive use of our own APIs in examples and tests
- **Example validation**: Every example must compile and demonstrate best practices
- **Architecture reviews**: Regular assessment of API design decisions
- **User feedback**: Direct feedback from real-world usage

## üìù Contributing Guidelines

When contributing to TurboMCP:

1. **Follow TDD religiously** - Tests first, implementation second, no exceptions
2. **Always ask "Is this production-ready?"** before proposing changes
3. **Research best-in-class solutions** - Use WebSearch for latest docs, check crates.io for maintained libraries
4. **Validate through examples** - if examples become more complex, reconsider the API
5. **Maintain Send-safety** throughout all async APIs
6. **Document with examples** showing real-world usage patterns
7. **Test comprehensively** - Real services, edge cases, error scenarios, performance
8. **Follow the "ultrathink" principle** - Deep analysis before coding, never quick fixes
9. **Use TodoWrite for planning** - Rich context, never placeholders in code
10. **Run ALL enforcement checks** - The Anti-Gaslighting Protocol is mandatory

### Testing Requirements - ZERO TOLERANCE

When writing tests:
- ‚ùå **NEVER** write `assert_eq!(2 + 2, 4)` or similar mathematical gaslighting
- ‚ùå **NEVER** use `let _ = result` patterns that discard results without validation
- ‚ùå **NEVER** test third-party libraries (like schemars) instead of our implementation
- ‚ùå **NEVER** create empty test functions or tests with no assertions
- ‚ùå **NEVER** use mocks when real implementation is available
- ‚úÖ **ALWAYS** test actual macro-generated output and schemas
- ‚úÖ **ALWAYS** validate results from async operations and function calls
- ‚úÖ **ALWAYS** test the complete integration chain, not just isolated parts
- ‚úÖ **ALWAYS** include meaningful assertions that validate actual behavior
- ‚úÖ **ALWAYS** ensure tests would catch real bugs (like the schema bug)

### The Ultrathink Method - MANDATORY WORKFLOW

**THIS IS NOT OPTIONAL. Apply this to EVERY task:**

1. **Analyze deeply** 
   - Understand the complete architecture before acting
   - Research existing patterns in the codebase
   - Identify all dependencies and interactions
   
2. **Plan comprehensively** 
   - Use TodoWrite to track all aspects with rich context
   - Break down complex tasks into testable units
   - Define success criteria for each component
   
3. **Research thoroughly**
   - Use WebSearch for latest library documentation
   - Check crates.io for best-in-class implementations
   - Verify version compatibility and maintenance status
   
4. **Test first (TDD)**
   - Write comprehensive tests before any implementation
   - Tests must fail initially and validate real behavior
   - Cover edge cases, error paths, and performance
   
5. **Implement methodically** 
   - Production-grade code only, no shortcuts
   - Follow patterns from world-class libraries
   - Optimize for maintainability and performance
   
6. **Validate thoroughly** 
   - Run all tests against real services
   - Execute the Anti-Gaslighting Protocol
   - Verify examples still compile and work
   
7. **Enforce continuously** 
   - Automated quality gates must all pass
   - No claiming completion until ALL checks pass
   - Document any discovered issues for future prevention

**Remember**: "Ultrathink then ultra implement" means solving the root problem completely with world-class engineering, not applying quick fixes or creating technical debt.

## üìã Context-Rich TODO Management

### TODO Philosophy - Planning Without Placeholders

**CRITICAL: TodoWrite is for PLANNING and TRACKING, not for deferring work.**

- **Rich Context**: Each TODO must include enough context to pick up work months later
- **Implementation Details**: Include specific file paths, code patterns, and architectural decisions
- **Progress Tracking**: Clear status and dependencies
- **Quality Gates**: Reference relevant specs, benchmarks, and validation criteria
- **NO PLACEHOLDERS**: Never use todos as an excuse to leave `todo!()` in code
- **IMMEDIATE ACTION**: When you create a todo, work on it immediately unless blocked
- **TDD PLANNING**: Each todo should specify what tests need to be written first

### TODO Template Format
```markdown
## [STATUS] Feature Name - Brief Description

**Context**: Why this TODO exists and what problem it solves
**Location**: Specific files/modules that need changes
**Dependencies**: What must be completed first
**Implementation Notes**: Key architectural decisions and patterns to follow
**Validation**: How to verify completion (tests, benchmarks, spec compliance)
**References**: Links to specs, documentation, examples

### Detailed Implementation Steps:
1. [ ] Specific step with file location
2. [ ] Another step with expected outcome
3. [ ] Validation step with success criteria

### Code Patterns to Follow:
- Reference existing patterns in the codebase
- Link to architectural decisions
- Include performance/security considerations
```

### TODO Status Levels
- **üî¥ CRITICAL**: Blocking MCP compliance or major functionality
- **üü° HIGH**: Important features affecting user experience  
- **üü¢ MEDIUM**: Enhancements and optimizations
- **üîµ LOW**: Nice-to-have improvements

### Production Commands

Essential commands for production development:
```bash
# Run comprehensive integration tests (our pride and joy)
make test-integration

# Run zero-tolerance test quality enforcement 
make test-enforce

# Run everything including quality enforcement
make test-all

# Comprehensive test suite (original)
make test
```

---

## üéØ FINAL REMINDERS - ZERO TOLERANCE

**BEFORE YOU WRITE A SINGLE LINE OF CODE:**
1. Have you completed the Ultrathink Method steps 1-3?
2. Have you written failing tests first (TDD)?
3. Have you researched best-in-class libraries?
4. Are you about to create a mock or placeholder? STOP.

**BEFORE YOU CLAIM ANY TASK IS COMPLETE:**
1. Run the ENTIRE Anti-Gaslighting Protocol
2. Verify ALL tests pass with real implementations
3. Ensure NO placeholders, mocks, or shortcuts exist
4. Confirm examples still compile and work

**IF YOU'RE ABOUT TO:**
- Write `todo!()` or `unimplemented!()` - STOP, use TodoWrite instead
- Create a mock service - STOP, use Docker/Testcontainers
- Test against third-party libraries - STOP, test YOUR implementation
- Claim "robust implementation" with shortcuts - STOP, that's gaslighting
- Skip writing tests first - STOP, TDD is mandatory

*"The best APIs are those where the simple things are simple, the complex things are possible, and users never have to think about the implementation complexity we've solved for them."*

*"No more mocks, no more gaslighting, no more shortcuts. Only production-grade, enterprise-ready code."*

*"Ultrathink to the moon - methodical, comprehensive, uncompromising excellence."*

*"Test-Driven Development or nothing. World-class engineering or nothing. Production-grade or nothing."*

**DO NOT MAKE COMMITS EVER UNLESS EXPLICITLY ASKED**